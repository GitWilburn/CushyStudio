// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
export const parser = LRParser.deserialize({
  version: 14,
  states: "!QOVQPOOOVQPO'#CaOOQO'#Cf'#CfOOQO'#Cb'#CbQVQPOOOeQPO,58{OOQO-E6`-E6`OOQO1G.g1G.g",
  stateData: "v~OXOS~OQQORQOSQOZPO~OQQORQOSQOZPO[VO~O",
  goto: "rZPPPPP[bPPPlXQOPSTQSOQTPTUSTXROPST",
  nodeNames: "âš  File Identifier Number String WeightedExpression",
  maxTerm: 12,
  nodeProps: [
    ["group", -4,2,3,4,5,"Expression"]
  ],
  skippedNodes: [0],
  repeatNodeCount: 1,
  tokenData: "$[~RaX^!Wpq!Wrs!{xy#jyz#o!Q![#t!c!}#|#R#S#|#T#o#|#y#z!W$f$g!W#BY#BZ!W$IS$I_!W$I|$JO!W$JT$JU!W$KV$KW!W&FU&FV!W~!]YX~X^!Wpq!W#y#z!W$f$g!W#BY#BZ!W$IS$I_!W$I|$JO!W$JT$JU!W$KV$KW!W&FU&FV!W~#OTOr!{rs#_s;'S!{;'S;=`#d<%lO!{~#dOS~~#gP;=`<%l!{~#oOZ~~#tO[~~#yPR~!Q![#t~$RRQ~!c!}#|#R#S#|#T#o#|",
  tokenizers: [0],
  topRules: {"File":[0,1]},
  tokenPrec: 0
})
